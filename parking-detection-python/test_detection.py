import cv2
import numpy as np
import os
from ultralytics import YOLO

# ƒê∆∞·ªùng d·∫´n file
YOLO_MODEL_PATH = 'z.pt'
IMAGE_PATH = 'aerial2.jpg'
OUTPUT_IMAGE_PATH = 'test_detection_result.jpg'
CONFIDENCE_THRESHOLD = 0.1

def resize_with_aspect_ratio(image, max_width=1280, max_height=720):
    """
    Resizes 'image' so that neither width nor height exceed the given maxima,
    preserving aspect ratio. Returns (resized_image, scale_factor).
    """
    h, w = image.shape[:2]
    scale = min(max_width / w, max_height / h)
    new_w = int(w * scale)
    new_h = int(h * scale)
    resized = cv2.resize(image, (new_w, new_h), interpolation=cv2.INTER_AREA)
    return resized, scale

def test_yolo_detection():
    """
    Test YOLO detection tr√™n ·∫£nh aerial2.jpg
    """
    print("=== KI·ªÇM TRA YOLO DETECTION ===")
    
    # 1. Ki·ªÉm tra file t·ªìn t·∫°i
    if not os.path.exists(YOLO_MODEL_PATH):
        print(f"‚ùå Kh√¥ng t√¨m th·∫•y YOLO model: {YOLO_MODEL_PATH}")
        return
    
    if not os.path.exists(IMAGE_PATH):
        print(f"‚ùå Kh√¥ng t√¨m th·∫•y ·∫£nh: {IMAGE_PATH}")
        return
    
    print(f"‚úÖ T√¨m th·∫•y YOLO model: {YOLO_MODEL_PATH}")
    print(f"‚úÖ T√¨m th·∫•y ·∫£nh: {IMAGE_PATH}")
    
    # 2. Load YOLO model
    print("üîÑ ƒêang load YOLO model...")
    model = YOLO(YOLO_MODEL_PATH)
    print("‚úÖ YOLO model ƒë√£ ƒë∆∞·ª£c load th√†nh c√¥ng!")
    
    # 3. Load v√† resize ·∫£nh
    print("üîÑ ƒêang load ·∫£nh...")
    orig_img = cv2.imread(IMAGE_PATH)
    if orig_img is None:
        print(f"‚ùå Kh√¥ng th·ªÉ load ·∫£nh: {IMAGE_PATH}")
        return
    
    resized_img, scale = resize_with_aspect_ratio(orig_img, 1280, 720)
    print(f"‚úÖ ·∫¢nh ƒë√£ ƒë∆∞·ª£c resize: {resized_img.shape}")
    
    # 4. Ch·∫°y YOLO detection
    print("üîÑ ƒêang ch·∫°y YOLO detection...")
    results = model(resized_img, conf=CONFIDENCE_THRESHOLD)
    
    # 5. V·∫Ω k·∫øt qu·∫£ l√™n ·∫£nh
    detected_cars = 0
    annotated_img = resized_img.copy()
    
    for result in results:
        if result.boxes is not None:
            for box, cls_i in zip(result.boxes.xyxy, result.boxes.cls):
                cls_name = result.names[int(cls_i)]
                confidence = result.boxes.conf[0] if result.boxes.conf is not None else 0
                
                # Ch·ªâ hi·ªÉn th·ªã xe h∆°i
                if cls_name == "car":
                    detected_cars += 1
                    x1, y1, x2, y2 = map(int, box)
                    
                    # V·∫Ω bounding box
                    cv2.rectangle(annotated_img, (x1, y1), (x2, y2), (0, 255, 0), 2)
                    
                    # V·∫Ω label
                    label = f"{cls_name}: {confidence:.2f}"
                    cv2.putText(annotated_img, label, (x1, y1-10), 
                              cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)
    
    print(f"‚úÖ Ph√°t hi·ªán ƒë∆∞·ª£c {detected_cars} xe h∆°i!")
    
    # 6. L∆∞u k·∫øt qu·∫£
    cv2.imwrite(OUTPUT_IMAGE_PATH, annotated_img)
    print(f"‚úÖ K·∫øt qu·∫£ ƒë√£ ƒë∆∞·ª£c l∆∞u v√†o: {OUTPUT_IMAGE_PATH}")
    
    # 7. Hi·ªÉn th·ªã k·∫øt qu·∫£ (t√πy ch·ªçn)
    print("\nüìã T√≥m t·∫Øt:")
    print(f"   - S·ªë xe ph√°t hi·ªán: {detected_cars}")
    print(f"   - Confidence threshold: {CONFIDENCE_THRESHOLD}")
    print(f"   - K√≠ch th∆∞·ªõc ·∫£nh sau resize: {resized_img.shape}")
    print(f"   - File k·∫øt qu·∫£: {OUTPUT_IMAGE_PATH}")

if __name__ == "__main__":
    test_yolo_detection()
