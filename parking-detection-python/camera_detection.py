import cv2
import numpy as np
import os
from ultralytics import YOLO
import time

# ÄÆ°á»ng dáº«n file
YOLO_MODEL_PATH = 'z.pt'
CONFIDENCE_THRESHOLD = 0.1

def resize_with_aspect_ratio(image, max_width=1280, max_height=720):
    """
    Resizes 'image' so that neither width nor height exceed the given maxima,
    preserving aspect ratio. Returns (resized_image, scale_factor).
    """
    h, w = image.shape[:2]
    scale = min(max_width / w, max_height / h)
    new_w = int(w * scale)
    new_h = int(h * scale)
    resized = cv2.resize(image, (new_w, new_h), interpolation=cv2.INTER_AREA)
    return resized, scale

def detect_cars_from_camera():
    """
    PhÃ¡t hiá»‡n xe hÆ¡i tá»« camera thá»i gian thá»±c
    """
    print("=== PHÃT HIá»†N XE HÆ I Tá»ª CAMERA ===")
    
    # 1. Kiá»ƒm tra YOLO model
    if not os.path.exists(YOLO_MODEL_PATH):
        print(f"âŒ KhÃ´ng tÃ¬m tháº¥y YOLO model: {YOLO_MODEL_PATH}")
        return
    
    print(f"âœ… TÃ¬m tháº¥y YOLO model: {YOLO_MODEL_PATH}")
    
    # 2. Load YOLO model
    print("ğŸ”„ Äang load YOLO model...")
    model = YOLO(YOLO_MODEL_PATH)
    print("âœ… YOLO model Ä‘Ã£ Ä‘Æ°á»£c load thÃ nh cÃ´ng!")
    
    # 3. Khá»Ÿi táº¡o camera
    print("ğŸ”„ Äang káº¿t ná»‘i camera...")
    cap = cv2.VideoCapture(0)  # 0 lÃ  camera máº·c Ä‘á»‹nh
    
    if not cap.isOpened():
        print("âŒ KhÃ´ng thá»ƒ má»Ÿ camera!")
        print("ğŸ’¡ HÆ°á»›ng dáº«n kháº¯c phá»¥c:")
        print("   - Kiá»ƒm tra camera cÃ³ Ä‘Æ°á»£c káº¿t ná»‘i khÃ´ng")
        print("   - Thá»­ thay Ä‘á»•i camera index (0, 1, 2...)")
        print("   - Äáº£m báº£o khÃ´ng cÃ³ á»©ng dá»¥ng nÃ o khÃ¡c Ä‘ang sá»­ dá»¥ng camera")
        return
    
    # CÃ i Ä‘áº·t Ä‘á»™ phÃ¢n giáº£i camera
    cap.set(cv2.CAP_PROP_FRAME_WIDTH, 1280)
    cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 720)
    
    # Láº¥y thÃ´ng tin camera thá»±c táº¿
    actual_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    actual_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
    fps = cap.get(cv2.CAP_PROP_FPS)
    
    print(f"âœ… Camera Ä‘Ã£ káº¿t ná»‘i thÃ nh cÃ´ng!")
    print(f"   - Äá»™ phÃ¢n giáº£i: {actual_width}x{actual_height}")
    print(f"   - FPS: {fps}")
    print("\nğŸ® Äiá»u khiá»ƒn:")
    print("   - Nháº¥n 'q' Ä‘á»ƒ thoÃ¡t")
    print("   - Nháº¥n 's' Ä‘á»ƒ chá»¥p áº£nh")
    print("   - Nháº¥n 'p' Ä‘á»ƒ táº¡m dá»«ng/tiáº¿p tá»¥c")
    
    paused = False
    frame_count = 0
    start_time = time.time()
    
    try:
        while True:
            if not paused:
                ret, frame = cap.read()
                if not ret:
                    print("âŒ KhÃ´ng thá»ƒ Ä‘á»c frame tá»« camera")
                    break
                
                frame_count += 1
                
                # 4. Resize frame Ä‘á»ƒ tÄƒng tá»‘c Ä‘á»™ xá»­ lÃ½
                resized_frame, scale = resize_with_aspect_ratio(frame, 1280, 720)
                
                # 5. Cháº¡y YOLO detection
                results = model(resized_frame, conf=CONFIDENCE_THRESHOLD, verbose=False)
                
                # 6. Váº½ káº¿t quáº£ lÃªn frame
                detected_cars = 0
                detected_objects = {}
                annotated_frame = resized_frame.copy()
                
                for result in results:
                    if result.boxes is not None:
                        for i, (box, cls_i, conf) in enumerate(zip(result.boxes.xyxy, result.boxes.cls, result.boxes.conf)):
                            cls_name = result.names[int(cls_i)]
                            confidence = float(conf)
                            
                            # Äáº¿m táº¥t cáº£ cÃ¡c Ä‘á»‘i tÆ°á»£ng
                            if cls_name not in detected_objects:
                                detected_objects[cls_name] = 0
                            detected_objects[cls_name] += 1
                            
                            x1, y1, x2, y2 = map(int, box)
                            
                            # Chá»n mÃ u dá»±a trÃªn loáº¡i xe
                            if cls_name == "car":
                                color = (0, 255, 0)  # Xanh lÃ¡ cho xe hÆ¡i
                                detected_cars += 1
                            elif cls_name == "truck":
                                color = (255, 0, 0)  # Xanh dÆ°Æ¡ng cho xe táº£i
                            elif cls_name == "bus":
                                color = (0, 0, 255)  # Äá» cho xe buÃ½t
                            elif cls_name == "motorcycle":
                                color = (255, 255, 0)  # VÃ ng cho xe mÃ¡y
                            else:
                                color = (128, 128, 128)  # XÃ¡m cho cÃ¡c Ä‘á»‘i tÆ°á»£ng khÃ¡c
                            
                            # Váº½ bounding box
                            cv2.rectangle(annotated_frame, (x1, y1), (x2, y2), color, 2)
                            
                            # Váº½ label vá»›i confidence
                            label = f"{cls_name}: {confidence:.2f}"
                            label_size = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 2)[0]
                            
                            # Váº½ ná»n cho text
                            cv2.rectangle(annotated_frame, (x1, y1-label_size[1]-10), 
                                        (x1+label_size[0], y1), color, -1)
                            
                            # Váº½ text
                            cv2.putText(annotated_frame, label, (x1, y1-5), 
                                      cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2)
                
                # 7. Váº½ thÃ´ng tin thá»‘ng kÃª
                current_time = time.time()
                elapsed_time = current_time - start_time
                current_fps = frame_count / elapsed_time if elapsed_time > 0 else 0
                
                # Táº¡o thÃ´ng tin hiá»ƒn thá»‹
                info_lines = [
                    f"FPS: {current_fps:.1f}",
                    f"Frame: {frame_count}",
                    f"Cars: {detected_cars}"
                ]
                
                # ThÃªm thÃ´ng tin vá» cÃ¡c Ä‘á»‘i tÆ°á»£ng khÃ¡c
                for obj_name, count in detected_objects.items():
                    if obj_name != "car":
                        info_lines.append(f"{obj_name.title()}: {count}")
                
                # Váº½ background cho thÃ´ng tin
                info_height = len(info_lines) * 25 + 10
                cv2.rectangle(annotated_frame, (10, 10), (200, 10 + info_height), (0, 0, 0), -1)
                
                # Váº½ thÃ´ng tin
                for i, line in enumerate(info_lines):
                    y_pos = 30 + i * 25
                    cv2.putText(annotated_frame, line, (15, y_pos), 
                              cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)
                
                # 8. Hiá»ƒn thá»‹ frame
                cv2.imshow('YOLO Car Detection - Camera', annotated_frame)
            
            # 9. Xá»­ lÃ½ phÃ­m nháº¥n
            key = cv2.waitKey(1) & 0xFF
            
            if key == ord('q'):
                print("ğŸ”´ Äang thoÃ¡t...")
                break
            elif key == ord('s'):
                # Chá»¥p áº£nh
                timestamp = int(time.time())
                filename = f"camera_capture_{timestamp}.jpg"
                if not paused:
                    cv2.imwrite(filename, annotated_frame)
                    print(f"ğŸ“¸ ÄÃ£ chá»¥p áº£nh: {filename}")
                else:
                    print("âš ï¸ KhÃ´ng thá»ƒ chá»¥p áº£nh khi Ä‘ang táº¡m dá»«ng")
            elif key == ord('p'):
                # Táº¡m dá»«ng/tiáº¿p tá»¥c
                paused = not paused
                if paused:
                    print("â¸ï¸ ÄÃ£ táº¡m dá»«ng")
                else:
                    print("â–¶ï¸ Tiáº¿p tá»¥c")
    
    except KeyboardInterrupt:
        print("\nğŸ”´ ÄÃ£ dá»«ng bá»Ÿi ngÆ°á»i dÃ¹ng (Ctrl+C)")
    
    finally:
        # 10. Dá»n dáº¹p
        cap.release()
        cv2.destroyAllWindows()
        
        # In thá»‘ng kÃª cuá»‘i
        total_time = time.time() - start_time
        avg_fps = frame_count / total_time if total_time > 0 else 0
        
        print(f"\nğŸ“Š Thá»‘ng kÃª:")
        print(f"   - Tá»•ng sá»‘ frame: {frame_count}")
        print(f"   - Thá»i gian cháº¡y: {total_time:.1f}s")
        print(f"   - FPS trung bÃ¬nh: {avg_fps:.1f}")
        print("âœ… ÄÃ£ Ä‘Ã³ng camera vÃ  thoÃ¡t chÆ°Æ¡ng trÃ¬nh")

def test_camera_availability():
    """
    Kiá»ƒm tra camera cÃ³ sáºµn khÃ´ng
    """
    print("ğŸ” Äang kiá»ƒm tra camera cÃ³ sáºµn...")
    
    for i in range(5):  # Kiá»ƒm tra camera index tá»« 0 Ä‘áº¿n 4
        cap = cv2.VideoCapture(i)
        if cap.isOpened():
            ret, frame = cap.read()
            if ret:
                height, width = frame.shape[:2]
                print(f"âœ… Camera {i}: {width}x{height}")
            else:
                print(f"âŒ Camera {i}: KhÃ´ng thá»ƒ Ä‘á»c frame")
            cap.release()
        else:
            print(f"âŒ Camera {i}: KhÃ´ng thá»ƒ má»Ÿ")
    
    print("\nğŸ’¡ Náº¿u khÃ´ng cÃ³ camera nÃ o hoáº¡t Ä‘á»™ng:")
    print("   1. Kiá»ƒm tra camera Ä‘Ã£ Ä‘Æ°á»£c káº¿t ná»‘i")
    print("   2. Kiá»ƒm tra driver camera")
    print("   3. Äáº£m báº£o khÃ´ng cÃ³ app nÃ o khÃ¡c Ä‘ang dÃ¹ng camera")
    print("   4. Thá»­ khá»Ÿi Ä‘á»™ng láº¡i mÃ¡y tÃ­nh")

if __name__ == "__main__":
    print("ğŸš— CHÆ¯Æ NG TRÃŒNH PHÃT HIá»†N XE HÆ I Tá»ª CAMERA ğŸš—")
    print("\nChá»n cháº¿ Ä‘á»™:")
    print("1. Cháº¡y detection tá»« camera")
    print("2. Kiá»ƒm tra camera cÃ³ sáºµn")
    
    choice = input("\nNháº­p lá»±a chá»n (1/2): ").strip()
    
    if choice == "1":
        detect_cars_from_camera()
    elif choice == "2":
        test_camera_availability()
    else:
        print("âŒ Lá»±a chá»n khÃ´ng há»£p lá»‡!")
        print("Cháº¡y cháº¿ Ä‘á»™ máº·c Ä‘á»‹nh...")
        detect_cars_from_camera()
